{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade pip\n",
    "!pip3 install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this exercise you will train a CNN on the FULL Cats-v-dogs dataset\n",
    "# This will require you doing a lot of data preprocessing because\n",
    "# the dataset isn't split into training and validation for you\n",
    "# This code block has all the required inputs\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "\n",
    "# This code block downloads the full Cats-v-Dogs dataset and stores it as \n",
    "# cats-and-dogs.zip. It then unzips it to /tmp\n",
    "# which will create a tmp/PetImages directory containing subdirectories\n",
    "# called 'Cat' and 'Dog' (that's how the original researchers structured it)\n",
    "# If the URL doesn't work, \n",
    "# .   visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
    "# And right click on the 'Download Manually' link to get a new URL\n",
    "\n",
    "#!wget --no-check-certificate \\\n",
    "#    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n",
    "#    -O \"/tmp/cats-and-dogs.zip\"\n",
    "\n",
    "#local_zip = '/tmp/cats-and-dogs.zip'\n",
    "#zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "#zip_ref.extractall('/tmp')\n",
    "#zip_ref.close()\n",
    "\n",
    "\n",
    "print(len(os.listdir('./PetImages/Cat/')))\n",
    "print(len(os.listdir('./PetImages/Dog/')))\n",
    "\n",
    "# Expected Output:\n",
    "# 12501\n",
    "# 12501\n",
    "\n",
    "# Use os.mkdir to create your directories\n",
    "# You will need a directory for cats-v-dogs, and subdirectories for training\n",
    "# and testing. These in turn will need subdirectories for 'cats' and 'dogs'\n",
    "try:\n",
    "    os.makedirs(\"training/dogs\")\n",
    "    os.makedirs(\"training/cats\")\n",
    "    os.makedirs(\"validation/dogs\")\n",
    "    os.makedirs(\"validation/cats\")\n",
    "except OSError as e:\n",
    "    print (\"Exception: \",e)\n",
    "    pass\n",
    "\n",
    "\n",
    "# Write a python function called split_data which takes\n",
    "# a SOURCE directory containing the files\n",
    "# a TRAINING directory that a portion of the files will be copied to\n",
    "# a TESTING directory that a portion of the files will be copie to\n",
    "# a SPLIT SIZE to determine the portion\n",
    "# The files should also be randomized, so that the training set is a random\n",
    "# X% of the files, and the test set is the remaining files\n",
    "# SO, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9\n",
    "# Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir\n",
    "# and 10% of the images will be copied to the TESTING dir\n",
    "# Also -- All images should be checked, and if they have a zero file length,\n",
    "# they will not be copied over\n",
    "#\n",
    "# os.listdir(DIRECTORY) gives you a listing of the contents of that directory\n",
    "# os.path.getsize(PATH) gives you the size of the file\n",
    "# copyfile(source, destination) copies a file from source to destination\n",
    "# random.sample(list, len(list)) shuffles a list\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    files = os.listdir(SOURCE)#[:1000]\n",
    "    all_size = len(files)\n",
    "    random.sample(files, all_size)\n",
    "    split_point = int(all_size*SPLIT_SIZE)\n",
    "    for f in files[:split_point]:\n",
    "       src = os.path.join(SOURCE, f)\n",
    "       dst = os.path.join(TRAINING, f)\n",
    "       if os.path.getsize(src) > 0:\n",
    "          copyfile(src, dst)  \n",
    "#          print(\"copying: \", f)\n",
    "       else:\n",
    "          print(\"skipping empty file: \", f)\n",
    "\n",
    "    for f in files[split_point:]:\n",
    "       src = os.path.join(SOURCE, f)\n",
    "       dst = os.path.join(TESTING, f)\n",
    "       if os.path.getsize(src) > 0:\n",
    "          copyfile(src, dst)  \n",
    "#          print(\"copying: \", f)\n",
    "       else:\n",
    "          print(\"skipping empty file: \", f)\n",
    "\n",
    "    \n",
    "# YOUR CODE STARTS HERE\n",
    "# YOUR CODE ENDS HERE\n",
    "train_dir = \"./training\"\n",
    "validation_dir = \"./validation\"\n",
    "\n",
    "CAT_SOURCE_DIR = \"./PetImages/Cat/\"\n",
    "TRAINING_CATS_DIR = \"./training/cats/\"\n",
    "TESTING_CATS_DIR = \"./validation/cats/\"\n",
    "DOG_SOURCE_DIR = \"./PetImages/Dog/\"\n",
    "TRAINING_DOGS_DIR = \"./training/dogs/\"\n",
    "TESTING_DOGS_DIR = \"./validation/dogs/\"\n",
    "\n",
    "\n",
    "#\n",
    "split_size = .9\n",
    "#split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "#split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n",
    "\n",
    "# Expected output\n",
    "# 666.jpg is zero length, so ignoring\n",
    "# 11702.jpg is zero length, so ignoring\n",
    "\n",
    "print(len(os.listdir(TRAINING_CATS_DIR)))\n",
    "print(len(os.listdir(TRAINING_DOGS_DIR)))\n",
    "print(len(os.listdir(TESTING_CATS_DIR)))\n",
    "print(len(os.listdir(TESTING_DOGS_DIR)))\n",
    "\n",
    "# Expected output:\n",
    "# 11250\n",
    "# 11250\n",
    "# 1250\n",
    "# 1250\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\", input_shape=(150, 150, 3)),\n",
    "  tf.keras.layers.MaxPooling2D((2,2)),\n",
    "  tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "  tf.keras.layers.MaxPooling2D((2,2)),\n",
    "  tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "  tf.keras.layers.MaxPooling2D((2,2)),\n",
    "  tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "  tf.keras.layers.MaxPooling2D((2,2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from   tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import matplotlib    \n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show_activations(img_path):\n",
    "        # Let's define a new Model that will take an image as input, and will output\n",
    "        # intermediate representations for all layers in the previous model after\n",
    "        # the first.\n",
    "        successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "\n",
    "        #visualization_model = Model(img_input, successive_outputs)\n",
    "        visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
    "\n",
    "        img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
    "\n",
    "        x   = img_to_array(img)                           # Numpy array with shape (150, 150, 3)\n",
    "        x   = x.reshape((1,) + x.shape)                   # Numpy array with shape (1, 150, 150, 3)\n",
    "\n",
    "        # Rescale by 1/255\n",
    "        x /= 255.0\n",
    "\n",
    "        # Let's run our image through our network, thus obtaining all\n",
    "        # intermediate representations for this image.\n",
    "        successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "        # These are the names of the layers, so can have them as part of our plot\n",
    "        layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "        # -----------------------------------------------------------------------\n",
    "        # Now let's display our representations\n",
    "        # -----------------------------------------------------------------------\n",
    "        for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "          conv = (len(feature_map.shape) == 4)\n",
    "          if len(feature_map.shape) > 0:\n",
    "            \n",
    "            #-------------------------------------------\n",
    "            # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "            #-------------------------------------------\n",
    "            n_features = feature_map.shape[-1]  # number of features in the feature map\n",
    "            size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n",
    "            \n",
    "            # We will tile our images in this matrix\n",
    "            display_grid = np.zeros((size, size * n_features))\n",
    "            \n",
    "            #-------------------------------------------------\n",
    "            # Postprocess the feature to be visually palatable\n",
    "            #-------------------------------------------------\n",
    "            for i in range(n_features):\n",
    "              if conv:\n",
    "                  x  = feature_map[0, :, :, i]\n",
    "              else:\n",
    "                  new_shape = feature_map.shape\n",
    "                  block=64  \n",
    "                  if feature_map.shape[0] >= block:\n",
    "                      new_shape = (int(feature_map.shape[0]/block),block)\n",
    "                  x  = feature_map.reshape(new_shape)\n",
    "              x -= x.mean()\n",
    "              x /= x.std ()\n",
    "              x *=  64\n",
    "              x += 128\n",
    "              x  = np.clip(x, 0, 255).astype('uint8')\n",
    "              display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n",
    "\n",
    "            #-----------------\n",
    "            # Display the grid\n",
    "            #-----------------\n",
    "\n",
    "            scale = 40. / n_features\n",
    "            plt.figure( figsize=(scale * n_features, scale) )\n",
    "            plt.title ( layer_name )\n",
    "            plt.grid  ( False )\n",
    "            plt.imshow( display_grid, aspect='auto', cmap='viridis' ) \n",
    "            ts = time.time()\n",
    "\n",
    "def show_random():\n",
    "        # Directory with our training cat/dog pictures\n",
    "        train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "        train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "        # Directory with our validation cat/dog pictures\n",
    "        validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "        validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "\n",
    "        train_cat_fnames = os.listdir( train_cats_dir )\n",
    "        train_dog_fnames = os.listdir( train_dogs_dir )\n",
    "        cat_img_files = [os.path.join(train_cats_dir, f) for f in train_cat_fnames]\n",
    "        dog_img_files = [os.path.join(train_dogs_dir, f) for f in train_dog_fnames]\n",
    "\n",
    "        img_path = random.choice(cat_img_files + dog_img_files)\n",
    "        \n",
    "        show_activations(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.exit(0)\n",
    "\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255., rotation_range=90, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255., rotation_range=90, horizontal_flip=True)\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\"./training\", batch_size=batch_size, class_mode='binary', target_size=(150, 150))\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\"./validation\", batch_size=batch_size, class_mode='binary', target_size=(150, 150))\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "                              validation_data=validation_generator, \n",
    "                              steps_per_epoch=100, \n",
    "                              epochs=15, \n",
    "                              validation_steps=50,\n",
    "                              verbose=2)\n",
    "\n",
    "if history.history['val_acc'][-1] > history.history['val_acc'][0]:\n",
    "    model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc      = history.history[     'acc' ]\n",
    "val_acc  = history.history[ 'val_acc' ]\n",
    "loss     = history.history[    'loss' ]\n",
    "val_loss = history.history['val_loss' ]\n",
    "\n",
    "epochs   = range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot  ( epochs,     acc )\n",
    "plt.plot  ( epochs, val_acc )\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot  ( epochs,     loss )\n",
    "plt.plot  ( epochs, val_loss )\n",
    "plt.title ('Training and validation loss'   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
